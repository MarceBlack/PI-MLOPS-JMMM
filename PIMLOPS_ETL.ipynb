{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Individual #1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> DATAFT08 - Jorge Marcelo Mendez"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRIMERA PARTE\n",
    "\n",
    "a.  Importar las bibliotecas necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Ingesta de los datasets que voy a utilizar y me han sido suministrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos de cada plataforma en un dataframe (Cargar los archivos CSV)\n",
    "\n",
    "netflix_df = pd.read_csv(r\"DATASETS_Henry\\netflix_titles.csv\")\n",
    "amazon_prime_df = pd.read_csv(r\"DATASETS_Henry\\amazon_prime_titles.csv\")\n",
    "disney_df = pd.read_csv(r\"DATASETS_Henry\\disney_plus_titles.csv\")\n",
    "hulu_df = pd.read_csv(r\"DATASETS_Henry\\hulu_titles.csv\")\n",
    "\n",
    "\n",
    "# Definir una columna con el nombre de la plataforma correspondiente\n",
    "netflix_df['platform'] = 'netflix'\n",
    "amazon_prime_df['platform'] = 'amazon'\n",
    "disney_df['platform'] = 'disney'\n",
    "hulu_df['platform'] = 'hulu'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Reviso los datasets a utilizar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cada caso reviso el dataframe y la descripcion del mismo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NETFLIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reviso el registro netflix:\n",
    "netflix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reviso la descripción del dataset:\n",
    "netflix_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reviso la info del dataset: \n",
    "netflix_df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AMAZON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reviso el registro amazon prime:\n",
    "amazon_prime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reviso la descripción del dataset:\n",
    "amazon_prime_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reviso la info del dataset: \n",
    "amazon_prime_df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DISNEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reviso el registro disney:\n",
    "disney_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reviso la descripción del dataset:\n",
    "disney_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reviso la info del dataset: \n",
    "disney_df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HULU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reviso el registro hulu:\n",
    "hulu_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reviso la descripción del dataset:\n",
    "hulu_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reviso la info del dataset: \n",
    "hulu_df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SEGUNDA PARTE\n",
    "\n",
    "Transformacion de datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Generar campo id: Cada id se compondrá de la primera letra del nombre de la plataforma, seguido del show_id ya presente en los datasets (ejemplo para títulos de Amazon = as123)\n",
    "\n",
    "* Los valores nulos del campo rating deberán reemplazarse por el string “G” (corresponde al maturity rating: “general for all audiences”\n",
    "\n",
    "* De haber fechas, deberán tener el formato AAAA-mm-dd\n",
    "\n",
    "* Los campos de texto deberán estar en minúsculas, sin excepciones\n",
    "\n",
    "* El campo duration debe convertirse en dos campos: duration_int y duration_type. El primero será un integer y el segundo un string indicando la unidad de medición de duración: min (minutos) o season (temporadas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de realizar la transformacion de datos, veo por conveniente concatenar o unir los datasets en un solo dataframe para poder optimizar el codigo, ademas de que entiendo que mejorara la manipulacion de datos con FastAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar todos los dataframes en uno solo (la idea es darle una fuente unica de datos a la API)\n",
    "df = pd.concat([netflix_df, amazon_prime_df, disney_df, hulu_df], ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviso mi dataframe unificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora procedo a cumplir con cada uno de los puntos requeridos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar campo id\n",
    "df['id'] = df['platform'].str.slice(0, 1).str.lower() + df['show_id'].astype('str')\n",
    "\n",
    "# Reemplazar valores nulos de rating\n",
    "df['rating'] = df['rating'].fillna('G')\n",
    "\n",
    "# Reemplazar valores nulos ya que de no hacerlo, algunas consultas daran error\n",
    "df['duration'] = df['duration'].fillna(0)\n",
    "\n",
    "# Formatear fechas\n",
    "df['date_added'] = pd.to_datetime(df['date_added'], errors='coerce')\n",
    "df['date_added'] = df['date_added'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Convertir texto a minúsculas\n",
    "#df['type'] = df['type'].str.lower()\n",
    "#df['title'] = df['title'].str.lower()\n",
    "#df['director'] = df['director'].str.lower()\n",
    "#df['cast'] = df['cast'].str.lower()\n",
    "#df['country'] = df['country'].str.lower()\n",
    "#df['rating'] = df['rating'].str.lower()\n",
    "#df['duration'] = df['duration'].str.lower()\n",
    "#df['listed_in'] = df['listed_in'].str.lower()\n",
    "#df['description'] = df['description'].str.lower()\n",
    "df = df.apply(lambda x: x.str.lower() if x.dtype == 'object' else x)\n",
    "\n",
    "# Convertir duration a duration_int y duration_type\n",
    "df['duration_int'] = df['duration'].str.extract('(\\d+)', expand=False)\n",
    "df['duration_type'] = df['duration'].str.extract('([a-z]+)', expand=False)\n",
    "\n",
    "# Como debe convertirse en duration a duration_int y duration_type, corresponde borrarla\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['duration_int'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['duration_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformo el tipo de dato de la columna \"duration_int\" a entero:\n",
    "df['duration_int'] = df['duration_int'].astype(\"Int64\")\n",
    "\n",
    "#verifico que se haya hecho la transformación:\n",
    "print(df[\"duration_int\"].dtype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuevamente, reviso mis resultados en el dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reviso que los cambios se hayan aplicado correctamente:\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reviso nuevas descripciones de mi dataframe concatenado\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reviso nuevas info de mi dataframe concatenado\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reviso los tipos de datos en cada columna:\n",
    "print(df.dtypes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez verificada la nueva data consolidada exporto un SCV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporto el archivo a un csv nuevo:\n",
    "df.to_csv(\"streaming_completo.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
